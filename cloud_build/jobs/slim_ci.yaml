steps:

  - name: 'gcr.io/cloud-builders/gsutil'
    id: setup
    script: |
      sh cloud_build/pre_run_tasks.sh
    secretEnv: ['BQ_USER_JSON']

  - name: 'ghcr.io/dbt-labs/dbt-bigquery:1.6.0'
    id: dbt
    script: |
      python cloud_build/dbt_wrapper.py 'dbt deps'
      python cloud_build/dbt_wrapper.py 'dbt build --full-refresh -s state:modified+ --state prod_artifacts --target ci --defer'
    allowFailure: true
    env:
    - '_PR_NUMBER=$_PR_NUMBER'

  - name: 'python'
    id: post_run
    script: |
      pip install -r cloud_build/requirements.txt >> log.txt
      python cloud_build/post_run_tasks.py --write_state_artifacts n --alert_type ci
    env:
    - 'BUILD_ID=$BUILD_ID'
    - 'TRIGGER_NAME=$TRIGGER_NAME'
    - 'BRANCH_NAME=$BRANCH_NAME'
    secretEnv: ['SLACK_WEBHOOK']

availableSecrets:
  secretManager:
  - versionName: projects/$PROJECT_ID/secrets/BQ_USER_JSON/versions/latest
    env: 'BQ_USER_JSON'
  - versionName: projects/$PROJECT_ID/secrets/cloudbuild_dbt_slack_webhook/versions/latest
    env: 'SLACK_WEBHOOK'

options:
  logging: GCS_ONLY
  defaultLogsBucketBehavior: REGIONAL_USER_OWNED_BUCKET

timeout: 5400s
